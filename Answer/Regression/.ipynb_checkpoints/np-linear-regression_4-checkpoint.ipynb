{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with real data\n",
    "##### <div style='text-align:right'>made by Wonbin Kim</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import makedirs, path\n",
    "from util import printProgress, file_download, handling_xlsx, _shuffle\n",
    "\n",
    "data_path = './datasets'\n",
    "if not path.exists(data_path):\n",
    "    makedirs(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2. Energy-efficiency Data set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/energy+efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = path.join(data_path, 'ENB2012_data.xlsx')\n",
    "# file_path = file_download(data1_url, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = handling_xlsx(file_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y1', 'Y2'])\n"
     ]
    }
   ],
   "source": [
    "print(raw[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-work (1)\n",
    "### Splitting raw data into Covariate X and Response Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement 1\n",
    "keys = list(raw[0].keys())\n",
    "raw_data = np.array([[raw[i][k] for k in keys] for i in range(len(raw))]).astype(float)\n",
    "X = raw_data[:, :8]\n",
    "Y = raw_data[:, 8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-work (2)\n",
    "### adding 1 vector to data for representing bias\n",
    "\n",
    "### <center>\\\\(y = \\mathbf{w}^T\\phi(x)+b = [w_1, w_2, ... , w_d] \\cdot \\left[\\begin{matrix}{\\phi_1(x) \\\\ \\phi_2(x) \\\\ ... \\\\ \\phi_d(x)}\\end{matrix}\\right] + b \\\\)</center>\n",
    "\n",
    "### <center>\\\\(= [w_1, w_2, ... , w_d, b] \\cdot \\left[\\begin{matrix}{\\phi_1(x) \\\\ \\phi_2(x) \\\\ ... \\\\ \\phi_d(x) \\\\ \"1\"}\\end{matrix}\\right]\\\\)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_term(X):\n",
    "    return np.concatenate([X, np.ones([len(X), 1])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-work (3)\n",
    "### For estimation, Seperate X and Y into training set and test set.\n",
    "### Train : Test  = 0.7 : 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 8) (231, 8) (768, 8)\n"
     ]
    }
   ],
   "source": [
    "whole_X, whole_Y = _shuffle(X,Y)\n",
    "no_data = len(whole_X)\n",
    "no_training = int(no_data*0.7)\n",
    "train_X, train_Y = whole_X[:no_training], whole_Y[:no_training]\n",
    "test_X, test_Y = whole_X[no_training:], whole_Y[no_training:]\n",
    "\n",
    "print(train_X.shape, test_X.shape, whole_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Squares Method\n",
    "\n",
    "### <center>\\\\(\\mathcal{J}_{LS}(w)=\\frac{1}{2N}\\sum_{n=1}^{N}\\left(y_n-\\mathbf{w}^T\\phi(x_n)\\right)^2 = \\frac{1}{2N}||y-\\phi^T\\mathbf{w}||^2_2\\\\)</center> <br>\n",
    "### Find <center> \\\\( \\hat{\\mathbf{w}}_{LS} = \\arg \\min\\limits_{\\mathbf{W}} \\frac{1}{2}||y-\\phi^T\\mathbf{w}||^2_2\\\\) </center>\n",
    "\n",
    "where $\\phi(x) \\in \\mathbb{R}^{d\\times N}$ , $y \\in \\mathbb{R}^{k \\times N}$, and $\\mathbf{w} \\in \\mathbb{R}^{k\\times d}$. N, d, k denote the number of instances, the dimensionality of covariate X, and the dimentionality of response Y, respectively.\n",
    "\n",
    "### Caution!\n",
    "\n",
    "For implementational simplicity, X is transposed in practice. i.e. $ x \\in \\mathbb{R}^{N\\times D}$, a row represents a instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "def ls(x, y, w, b = 0., l=0.):\n",
    "    out = np.square(y-np.dot(x, w)-b)\n",
    "    if len(out.shape) == 2: \n",
    "        out = np.sum(out, axis=1)\n",
    "    return 0.5*np.mean(out)+0.5*l*np.sum(np.square(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_w(x, y, l = 0.):\n",
    "    x_mtx = np.dot(x.T, x)\n",
    "    shape = x_mtx.shape\n",
    "    inv_x_mtx = np.linalg.inv(x_mtx+ l*np.eye(shape[0]))\n",
    "    w = np.dot(inv_x_mtx, np.dot(x.T, y))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function & Generalization\n",
    "\n",
    "<img src='image/pic11.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Linear Squared Method - identity basis function\n",
    "\n",
    "### <center> \\\\( \\phi(\\mathbf{x}) = \\mathbf{x}\\\\) </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_X = add_bias_term(train_X)\n",
    "new_test_X = add_bias_term(test_X)\n",
    "new_whole_X = add_bias_term(whole_X)\n",
    "\n",
    "w_ls = find_w(new_train_X, train_Y)\n",
    "pred_y = np.dot(new_whole_X, w_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.31118585e+02  1.39477244e+02]\n",
      " [-4.87614914e+01 -5.83990410e+01]\n",
      " [ 5.03448451e+01  5.74108745e+01]\n",
      " [ 9.40861452e+01  1.09360049e+02]\n",
      " [ 3.92859159e+00  3.97491966e+00]\n",
      " [ 5.64965453e-02  2.55347186e-01]\n",
      " [ 1.95422434e+01  1.45637574e+01]\n",
      " [ 2.31384944e-01  7.93877066e-02]\n",
      " [ 9.72667507e+01  1.20182011e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(w_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result : Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066582.4125371163\n",
      "1051092.6525813031\n"
     ]
    }
   ],
   "source": [
    "print(ls(new_train_X, train_Y, w_ls)) # [4.17002527 5.33017311]\n",
    "print(ls(new_test_X, test_Y, w_ls))   # [4.51320678 4.55826841]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By sklearn\n",
    "### <center> \\\\( \\phi(\\mathbf{x}) = \\mathbf{x}\\\\) </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "lr = lm.LinearRegression()\n",
    "lr.fit(train_X, train_Y)\n",
    "pred_y = lr.predict(whole_X)\n",
    "w_ls = lr.coef_\n",
    "b_ls = lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.18811217e+01 -5.17007033e+11  5.17007033e+11  1.03401407e+12\n",
      "   3.92884991e+00  5.61136669e-02  1.95420426e+01  2.31226032e-01]\n",
      " [-8.37192772e+01 -3.16342859e+11  3.16342859e+11  6.32685719e+11\n",
      "   3.97518820e+00  2.55287484e-01  1.45636390e+01  7.94318249e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(w_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result : Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.502918709299651\n",
      "9.097687881237237\n"
     ]
    }
   ],
   "source": [
    "print(ls(train_X, train_Y, w_ls.T, b_ls)) # [4.17089996 5.33201875]\n",
    "print(ls(test_X, test_Y, w_ls.T, b_ls))   # [4.52692975 4.57075813]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
