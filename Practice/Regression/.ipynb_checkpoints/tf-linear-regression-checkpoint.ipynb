{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "from example import plotting, example5, example6\n",
    "%matplotlib inline\n",
    "\n",
    "# plotting 함수\n",
    "n_observations = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "## #1 데이터 확보 (Download, Generate, etc.)\n",
    "## #2 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training example 1\n",
    "### <center>\\\\(y = sin(x)+\\epsilon \\\\) </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y, whole_X, whole_Y = example5(False, n_observations, np.pi, 0.01)\n",
    "plotting([train_X, test_X], [train_Y, test_Y], label=['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training example 2\n",
    "### <center>\\\\(y = -x-sin(x)+\\epsilon \\\\) </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y, whole_X, whole_Y = example6(False, n_observations, np.pi, 0.01)\n",
    "plotting([train_X, test_X], [train_Y, test_Y], label=['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "## Function Form\n",
    "### <center>\\\\(y = Wx+b \\\\) </center>\n",
    "## Loss Function : (Mean Square Error)\n",
    "### <center> \\\\( L(y^*, y) = \\frac{1}{2n}\\sum_{i=1}^n||y^*_i - y_i||^2\\\\) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Loss function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ms_loss(y_true, y_pred, n_observations):\n",
    "    \"\"\"\n",
    "    Args\n",
    "     - y_true : actual value of y\n",
    "     - y_pred : prediction of y from our model\n",
    "     - a,b : meaningless arguments\n",
    "    Returns\n",
    "     - loss : our loss (MSE)\n",
    "    \n",
    "    Hint : tf.reduce_sum or tf.square, tf.sum\n",
    "    \"\"\"\n",
    "    with tf.name_scope('mean_square'):\n",
    "        ###\n",
    "        pass\n",
    "        ###\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 Regressor model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(x, a=None):\n",
    "    \"\"\"\n",
    "    Args\n",
    "     - x : input\n",
    "     - a : meaningless parameter\n",
    "    Returns\n",
    "     - y_pred : model result\n",
    "     - weights : meaningless return\n",
    "    \n",
    "    Hint : tf.Variable, \n",
    "    \"\"\"\n",
    "    with tf.name_scope('linear'):\n",
    "        ###\n",
    "        pass\n",
    "        ###\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3 Hyper-parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_param(learning_rate = 1e-2, max_iter=1000, n_observations=500, degree=1):\n",
    "    return {'learning_rate':learning_rate,\n",
    "            'max_iter':max_iter,\n",
    "            'n_observations':n_observations,\n",
    "            'iter':[int(max_iter/3),int(max_iter*2/3), int(max_iter)],\n",
    "            'degree':degree}\n",
    "\n",
    "hyper = hyper_param(max_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4 Network 구성\n",
    "### (1) Placeholder 설정\n",
    "### (2) Loss function 선언\n",
    "### (3) Model 정의\n",
    "### (4) Optimizer 선언 및 Variable 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #5 Training and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hint : tf.placeholder, tf.train.GradientDescentOptimizer(), tf.global_variables_initializer()\n",
    "\"\"\"\n",
    "def training_analysis(model_function, loss_function, example_function, hyper):\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None], name='input')\n",
    "    y_true = tf.placeholder(tf.float32, [None], name='y_true')\n",
    "    y_pred = model_function(x, hyper['degree'])\n",
    "\n",
    "    loss = loss_function(y_true, y_pred, hyper['n_observations'])\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(hyper['learning_rate']).minimize(loss)\n",
    "    with tf.Session() as sess:\n",
    "        \"\"\"\n",
    "            Training\n",
    "        \"\"\"\n",
    "        train_x, train_y, test_x, test_y, whole_x, whole_y = example_function(False, hyper['n_observations'], np.pi, 0.01)\n",
    "        train_x = np.squeeze(train_x)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for step in range(hyper['max_iter']):\n",
    "            _,train_loss = sess.run([train_step, loss], feed_dict={x:train_x, y_true:train_y})\n",
    "            if (step+1) % 100 == 0:\n",
    "                test_loss = sess.run(loss, feed_dict={x:np.squeeze(test_x), y_true:test_y})\n",
    "                print(\"{}th iteration, train_loss: {:.4f}, test_loss: {:.4f}\".format(step + 1, train_loss, test_loss))\n",
    "            \"\"\"\n",
    "                Analysis\n",
    "            \"\"\"     \n",
    "            if step == hyper['iter'][0]:\n",
    "                pred_1 = sess.run(y_pred, feed_dict={x:train_x, y_true:train_y})\n",
    "            if step == hyper['iter'][1]:\n",
    "                pred_2 = sess.run(y_pred, feed_dict={x:train_x, y_true:train_y})\n",
    "        pred_3 = sess.run(y_pred, feed_dict={x:train_x, y_true:train_y})\n",
    "    tf.reset_default_graph()\n",
    "    return [pred_1, pred_2, pred_3]\n",
    "\n",
    "def legend(hyper):\n",
    "    label = ['train','test']\n",
    "    for i in hyper['iter']:\n",
    "        label.append('iter_'+str(i))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyper = hyper_param(max_iter=1000, learning_rate=1e-4)\n",
    "y_pred_ms_1 = training_analysis(linear_model, get_ms_loss, example5, hyper)\n",
    "train_x, train_y, test_x, test_y, whole_x, whole_y = example5(False, n_observations, np.pi, 0.01)\n",
    "plotting([train_x, test_x]+[train_x for i in range(len(y_pred_ms_1))], [train_y,test_y]+y_pred_ms_1, label=legend(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred_ms_2 = training_analysis(linear_model, get_ms_loss, example6, hyper)\n",
    "train_x, train_y, test_x, test_y, whole_x, whole_y = example6(False, n_observations, np.pi, 0.01)\n",
    "plotting([train_x, test_x]+[train_x for i in range(len(y_pred_ms_2))], [train_y,test_y]+y_pred_ms_2, label=legend(hyper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Regression\n",
    "## Function Form\n",
    "### <center>\\\\(y = W\\Phi(x)+b \\\\) </center>\n",
    "## Mean Square Loss\n",
    "### <center> \\\\( L(y^*, y) = \\frac{1}{2n}\\sum_{i=1}^n||y^*_i - y_i||^2\\\\) </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_model(x, degree):\n",
    "    \"\"\"\n",
    "    Args\n",
    "     - x : input\n",
    "     - degree : degree of polynomial\n",
    "    Returns\n",
    "     - y_pred : model result\n",
    "     - weights : for L2 regularization.\n",
    "    \n",
    "    Hint : tf.Variable, \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope('polynomial'):\n",
    "        ###\n",
    "        pass\n",
    "        ###\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = hyper_param(learning_rate = 25e-4, max_iter=1000, degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "poly_1= training_analysis(nonlinear_model, get_ms_loss, example5, hyper)\n",
    "train_x, train_y, test_x, test_y, whole_x, whole_y = example5(False, n_observations, np.pi,0.01)\n",
    "plotting([train_x, test_x]+[train_x for i in range(len(poly_1))], [train_y, test_y]+poly_1, label=legend(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "poly_2= training_analysis(nonlinear_model, get_ms_loss, example6, hyper)\n",
    "train_x, train_y, test_x, test_y, whole_x, whole_y = example6(False, n_observations, np.pi,0.01)\n",
    "plotting([train_x, test_x]+[train_x for i in range(len(poly_2))], [train_y, test_y]+poly_2, label=legend(hyper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
